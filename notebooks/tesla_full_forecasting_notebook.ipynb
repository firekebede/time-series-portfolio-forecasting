{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d21064b5",
   "metadata": {},
   "source": [
    "\n",
    "# Tesla Stock Forecasting — ARIMA/SARIMA vs Multivariate LSTM (Full Notebook)\n",
    "\n",
    "**Contents:**\n",
    "1. Setup & configuration\n",
    "2. Load data (expects `Date,Open,High,Low,Close,Adj Close,Volume`)\n",
    "3. Feature engineering (technical indicators)\n",
    "4. Chronological split (configurable)\n",
    "5. ARIMA/SARIMA (univariate Close)\n",
    "6. Multivariate LSTM (Open,High,Low,Close,Volume + technicals)\n",
    "7. Forecast future trends (6–12 months) with intervals (ARIMA CI + LSTM MC Dropout)\n",
    "8. Metrics, plots, and interpretation\n",
    "\n",
    "> Edit the `DATA_PATH` cell to point at your CSV file, then run the notebook cells sequentially.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d0954c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Install required packages (uncomment and run if needed)\n",
    "# !pip install pandas numpy matplotlib scikit-learn pmdarima tensorflow statsmodels nbformat\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "\n",
    "# optional imports\n",
    "AUTO_ARIMA_AVAILABLE = True\n",
    "try:\n",
    "    from pmdarima import auto_arima\n",
    "except Exception:\n",
    "    AUTO_ARIMA_AVAILABLE = False\n",
    "\n",
    "TF_AVAILABLE = True\n",
    "try:\n",
    "    import tensorflow as tf\n",
    "    from tensorflow.keras.models import Sequential\n",
    "    from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "    from tensorflow.keras.callbacks import EarlyStopping\n",
    "except Exception:\n",
    "    TF_AVAILABLE = False\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "np.random.seed(42)\n",
    "print('Environment ready. TensorFlow available:', TF_AVAILABLE, 'pmdarima available:', AUTO_ARIMA_AVAILABLE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9369b2ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ==== CONFIG: edit these paths and parameters ====\n",
    "DATA_PATH = 'path/to/tesla.csv'   # <-- set this to your CSV file path\n",
    "DATE_COL = 'Date'\n",
    "TARGET_COL = 'Close'\n",
    "\n",
    "# Chronological split (edit as needed)\n",
    "TRAIN_START = '2015-01-01'\n",
    "TRAIN_END   = '2023-12-31'\n",
    "TEST_START  = '2024-01-01'\n",
    "TEST_END    = '2025-12-31'\n",
    "\n",
    "# SARIMA toggle & seasonality period (m)\n",
    "USE_SEASONAL = False\n",
    "M_SEASONAL = 5\n",
    "\n",
    "# LSTM hyperparameters (multivariate)\n",
    "LOOKBACK = 60\n",
    "LSTM_UNITS = 64\n",
    "LSTM_DROPOUT = 0.2\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 30\n",
    "PATIENCE = 5\n",
    "LR = 1e-3\n",
    "\n",
    "# Forecast horizon for Task 3 (business days; ~126 for 6 months, ~252 for 12 months)\n",
    "FORECAST_HORIZON = 252\n",
    "\n",
    "# MC Dropout runs for LSTM uncertainty (for Task 3)\n",
    "N_MC_SAMPLES = 100\n",
    "\n",
    "USE_TECHNICALS = True  # add SMAs, EMAs, RSI, MACD to LSTM features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "395cf673",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Utilities: load, split, evaluate, helpers\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from typing import Tuple\n",
    "\n",
    "def load_df(path: str, date_col: str) -> pd.DataFrame:\n",
    "    df = pd.read_csv(path)\n",
    "    df[date_col] = pd.to_datetime(df[date_col])\n",
    "    df = df.sort_values(date_col).set_index(date_col)\n",
    "    df = df.asfreq('B')  # business-day frequency\n",
    "    df = df.ffill().bfill()\n",
    "    return df\n",
    "\n",
    "def chronological_split_indexed(s: pd.Series, train_start, train_end, test_start, test_end):\n",
    "    train = s.loc[train_start:train_end]\n",
    "    test  = s.loc[test_start:test_end]\n",
    "    if len(train) == 0 or len(test) == 0:\n",
    "        raise ValueError('Train/test slice empty; adjust dates.')\n",
    "    return train, test\n",
    "\n",
    "def evaluate(y_true, y_pred):\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    rmse = mean_squared_error(y_true, y_pred, squared=False)\n",
    "    mape = np.mean(np.abs((y_true - y_pred) / (y_true + 1e-8))) * 100\n",
    "    return {'MAE': mae, 'RMSE': rmse, 'MAPE%': mape}\n",
    "\n",
    "def summarize_trend_and_uncertainty(fc_mean: np.ndarray, lower: np.ndarray, upper: np.ndarray):\n",
    "    x = np.arange(len(fc_mean)).reshape(-1,1)\n",
    "    lr = LinearRegression().fit(x, fc_mean.reshape(-1,1))\n",
    "    slope = float(lr.coef_[0,0])\n",
    "    widths = upper - lower\n",
    "    start_w = float(np.mean(widths[: max(1, len(widths)//6) ]))\n",
    "    end_w   = float(np.mean(widths[- max(1, len(widths)//6) :]))\n",
    "    widen_rate = (end_w - start_w) / (start_w + 1e-8)\n",
    "    return {'slope': slope, 'start_width': start_w, 'end_width': end_w, 'widen_rate': widen_rate}\n",
    "\n",
    "def plot_with_bands(history_idx, history_vals, fc_idx, mean_vals, lower_vals, upper_vals, title):\n",
    "    plt.figure(figsize=(10,4))\n",
    "    plt.plot(history_idx, history_vals, label='History')\n",
    "    plt.plot(fc_idx, mean_vals, label='Forecast (mean)')\n",
    "    plt.fill_between(fc_idx, lower_vals, upper_vals, alpha=0.2, label='Interval')\n",
    "    plt.title(title)\n",
    "    plt.xlabel('Date'); plt.ylabel('Close')\n",
    "    plt.legend(); plt.tight_layout(); plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "791b2c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load your CSV\n",
    "df = load_df(DATA_PATH, DATE_COL)\n",
    "print('Data loaded:', df.shape)\n",
    "display(df.head())\n",
    "display(df.describe().T)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1888672d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Feature engineering for LSTM: ensure required columns exist\n",
    "base_cols = ['Close','Open','High','Low','Volume']\n",
    "for c in base_cols:\n",
    "    if c not in df.columns:\n",
    "        raise ValueError(f\"Missing required column: {c}\")\n",
    "\n",
    "fe = df.copy()\n",
    "\n",
    "if USE_TECHNICALS:\n",
    "    # Moving averages\n",
    "    for w in [5,10,20]:\n",
    "        fe[f'SMA_{w}'] = fe['Close'].rolling(w).mean()\n",
    "    # EMAs\n",
    "    for w in [12,26]:\n",
    "        fe[f'EMA_{w}'] = fe['Close'].ewm(span=w, adjust=False).mean()\n",
    "    # RSI (14)\n",
    "    delta = fe['Close'].diff()\n",
    "    gain = delta.clip(lower=0).rolling(14).mean()\n",
    "    loss = (-delta.clip(upper=0)).rolling(14).mean()\n",
    "    rs = gain/(loss + 1e-8)\n",
    "    fe['RSI_14'] = 100 - (100/(1+rs))\n",
    "    # MACD & signal\n",
    "    ema12 = fe['Close'].ewm(span=12, adjust=False).mean()\n",
    "    ema26 = fe['Close'].ewm(span=26, adjust=False).mean()\n",
    "    fe['MACD'] = ema12 - ema26\n",
    "    fe['MACD_Signal'] = fe['MACD'].ewm(span=9, adjust=False).mean()\n",
    "\n",
    "fe = fe.dropna()\n",
    "print('Feature-engineered data shape:', fe.shape)\n",
    "display(fe.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb14da82",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Univariate target for ARIMA\n",
    "target = fe[TARGET_COL]\n",
    "train_y, test_y = chronological_split_indexed(target, TRAIN_START, TRAIN_END, TEST_START, TEST_END)\n",
    "print('Train len:', len(train_y), 'Test len:', len(test_y))\n",
    "\n",
    "# LSTM features: Close first then others + technicals\n",
    "feature_cols = [c for c in ['Close','Open','High','Low','Volume'] if c in fe.columns]\n",
    "extra_cols = [c for c in fe.columns if c not in feature_cols]\n",
    "feature_cols = feature_cols + extra_cols\n",
    "feat_train = fe.loc[TRAIN_START:TRAIN_END, feature_cols]\n",
    "feat_test  = fe.loc[TEST_START:TEST_END,  feature_cols]\n",
    "print('LSTM feature columns (sample):', feature_cols[:10], '... total:', len(feature_cols))\n",
    "display(feat_train.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c712304",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ARIMA / SARIMA fit and test-set forecast (univariate Close)\n",
    "h_test = len(test_y)\n",
    "\n",
    "if AUTO_ARIMA_AVAILABLE:\n",
    "    print('Using pmdarima.auto_arima for ARIMA/SARIMA selection...')\n",
    "    arima = auto_arima(train_y, seasonal=USE_SEASONAL, m=(M_SEASONAL if USE_SEASONAL else 1),\n",
    "                       trace=False, error_action='ignore', suppress_warnings=True, stepwise=True)\n",
    "    arima_fc_test = arima.predict(n_periods=h_test)\n",
    "    try:\n",
    "        res = arima.arima_res_\n",
    "        pred = res.get_forecast(steps=h_test)\n",
    "        ci = pred.conf_int(alpha=0.05)\n",
    "        arima_lower_test = ci.iloc[:,0].values\n",
    "        arima_upper_test = ci.iloc[:,1].values\n",
    "    except Exception:\n",
    "        resid_std = np.std(arima.resid())\n",
    "        arima_lower_test = arima_fc_test - 1.96*resid_std\n",
    "        arima_upper_test = arima_fc_test + 1.96*resid_std\n",
    "else:\n",
    "    from statsmodels.tsa.arima.model import ARIMA\n",
    "    best_aic = np.inf; best_fit=None\n",
    "    for p in [0,1,2,3]:\n",
    "        for d in [0,1,2]:\n",
    "            for q in [0,1,2]:\n",
    "                try:\n",
    "                    fit = ARIMA(train_y, order=(p,d,q)).fit()\n",
    "                    if fit.aic < best_aic:\n",
    "                        best_aic = fit.aic; best_fit = fit\n",
    "                except Exception:\n",
    "                    continue\n",
    "    if best_fit is None:\n",
    "        raise RuntimeError('ARIMA grid search failed.')\n",
    "    pred = best_fit.get_forecast(steps=h_test)\n",
    "    arima_fc_test = pred.predicted_mean.values\n",
    "    ci = pred.conf_int(alpha=0.05)\n",
    "    arima_lower_test = ci.iloc[:,0].values\n",
    "    arima_upper_test = ci.iloc[:,1].values\n",
    "\n",
    "arima_metrics_test = evaluate(test_y.values, arima_fc_test)\n",
    "print('ARIMA test metrics:', arima_metrics_test)\n",
    "\n",
    "plot_with_bands(train_y.index, train_y.values, test_y.index, arima_fc_test, arima_lower_test, arima_upper_test,\n",
    "                'ARIMA — Test Forecast (with 95% CI)')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e11d750",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if not TF_AVAILABLE:\n",
    "    raise RuntimeError('TensorFlow not available. Install tensorflow or tensorflow-cpu.')\n",
    "\n",
    "# Scale features jointly (fit scaler on train features)\n",
    "scaler = MinMaxScaler(feature_range=(0,1))\n",
    "train_vals = feat_train.values\n",
    "test_vals = feat_test.values\n",
    "scaler.fit(train_vals)\n",
    "train_scaled = scaler.transform(train_vals)\n",
    "test_scaled  = scaler.transform(test_vals)\n",
    "\n",
    "# Create supervised windows for training (multivariate)\n",
    "def create_supervised_multivar(arr, lookback):\n",
    "    X, y = [], []\n",
    "    for i in range(lookback, arr.shape[0]):\n",
    "        X.append(arr[i-lookback:i, :])\n",
    "        y.append(arr[i, 0])  # predict Close (first column)\n",
    "    return np.array(X), np.array(y).reshape(-1,1)\n",
    "\n",
    "X_train, y_train = create_supervised_multivar(train_scaled, LOOKBACK)\n",
    "print('X_train shape:', X_train.shape, 'y_train shape:', y_train.shape)\n",
    "\n",
    "model = Sequential([\n",
    "    LSTM(LSTM_UNITS, input_shape=(LOOKBACK, X_train.shape[2]), return_sequences=False),\n",
    "    Dropout(LSTM_DROPOUT),\n",
    "    Dense(1)\n",
    "])\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=LR), loss='mse')\n",
    "\n",
    "es = EarlyStopping(monitor='val_loss', patience=PATIENCE, restore_best_weights=True)\n",
    "history = model.fit(X_train, y_train, epochs=EPOCHS, batch_size=BATCH_SIZE, validation_split=0.1,\n",
    "                    shuffle=False, callbacks=[es], verbose=0)\n",
    "print('LSTM trained.')\n",
    "\n",
    "# Forecast on test set using recursive strategy (feeding predictions)\n",
    "history_seq = train_scaled.copy()\n",
    "preds_scaled = []\n",
    "for i in range(test_scaled.shape[0]):\n",
    "    window = history_seq[-LOOKBACK:, :].reshape(1, LOOKBACK, -1)\n",
    "    yhat = model.predict(window, verbose=0)[0,0]\n",
    "    preds_scaled.append(yhat)\n",
    "    # append new row: replace Close (col 0) with predicted scaled value, keep other features from test row\n",
    "    new_row = test_scaled[i].copy()\n",
    "    new_row[0] = yhat\n",
    "    history_seq = np.vstack([history_seq, new_row])\n",
    "\n",
    "# inverse scale predicted closes\n",
    "inv_template = np.zeros((len(preds_scaled), train_scaled.shape[1]))\n",
    "inv_template[:,0] = preds_scaled\n",
    "lstm_fc_test = scaler.inverse_transform(inv_template)[:,0]\n",
    "\n",
    "lstm_metrics_test = evaluate(test_y.values, lstm_fc_test)\n",
    "print('LSTM test metrics:', lstm_metrics_test)\n",
    "\n",
    "plot_with_bands(train_y.index, train_y.values, test_y.index, lstm_fc_test, \n",
    "                lstm_fc_test - 1.96*np.std(lstm_fc_test), lstm_fc_test + 1.96*np.std(lstm_fc_test),\n",
    "                'LSTM (Multivariate) — Test Forecast (naive intervals)')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2701a4e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ---- Task 3: Forecast future N business days ----\n",
    "from pandas.tseries.offsets import BDay\n",
    "\n",
    "last_date = fe.index[-1]\n",
    "future_index = pd.bdate_range(start=last_date + BDay(1), periods=FORECAST_HORIZON)\n",
    "\n",
    "# ARIMA on full history and forecast with CI\n",
    "if AUTO_ARIMA_AVAILABLE:\n",
    "    arima_full = auto_arima(fe[TARGET_COL], seasonal=USE_SEASONAL, m=(M_SEASONAL if USE_SEASONAL else 1),\n",
    "                            trace=False, error_action='ignore', suppress_warnings=True, stepwise=True)\n",
    "    arima_mean_future = arima_full.predict(n_periods=FORECAST_HORIZON)\n",
    "    try:\n",
    "        res = arima_full.arima_res_\n",
    "        pred = res.get_forecast(steps=FORECAST_HORIZON)\n",
    "        ci = pred.conf_int(alpha=0.05)\n",
    "        arima_lower_future = ci.iloc[:,0].values\n",
    "        arima_upper_future = ci.iloc[:,1].values\n",
    "    except Exception:\n",
    "        resid_std = np.std(arima_full.resid())\n",
    "        arima_lower_future = arima_mean_future - 1.96*resid_std\n",
    "        arima_upper_future = arima_mean_future + 1.96*resid_std\n",
    "else:\n",
    "    from statsmodels.tsa.arima.model import ARIMA\n",
    "    best_aic = np.inf; best_fit=None\n",
    "    for p in [0,1,2,3]:\n",
    "        for d in [0,1,2]:\n",
    "            for q in [0,1,2]:\n",
    "                try:\n",
    "                    fit = ARIMA(fe[TARGET_COL], order=(p,d,q)).fit()\n",
    "                    if fit.aic < best_aic:\n",
    "                        best_aic = fit.aic; best_fit = fit\n",
    "                except Exception:\n",
    "                    continue\n",
    "    if best_fit is None:\n",
    "        raise RuntimeError('ARIMA grid search failed.')\n",
    "    pred = best_fit.get_forecast(steps=FORECAST_HORIZON)\n",
    "    arima_mean_future = pred.predicted_mean.values\n",
    "    ci = pred.conf_int(alpha=0.05)\n",
    "    arima_lower_future = ci.iloc[:,0].values\n",
    "    arima_upper_future = ci.iloc[:,1].values\n",
    "\n",
    "plot_with_bands(fe.index, fe[TARGET_COL].values, future_index, arima_mean_future, arima_lower_future, arima_upper_future,\n",
    "                f'ARIMA — {FORECAST_HORIZON}-day Forecast with 95% CI')\n",
    "print('ARIMA summary:', summarize_trend_and_uncertainty(arima_mean_future, arima_lower_future, arima_upper_future))\n",
    "\n",
    "# LSTM (Univariate Close) with MC Dropout for uncertainty\n",
    "if not TF_AVAILABLE:\n",
    "    raise RuntimeError('TensorFlow not available for LSTM future forecasting.')\n",
    "\n",
    "# Prepare univariate scaled sequence\n",
    "close_vals = fe[TARGET_COL].values.astype(float)\n",
    "min_v, max_v = close_vals.min(), close_vals.max()\n",
    "def scale(x): return (x - min_v) / (max_v - min_v + 1e-9)\n",
    "def inv_scale(x): return x*(max_v - min_v + 1e-9) + min_v\n",
    "\n",
    "seq = scale(close_vals)\n",
    "# build training windows on full data\n",
    "X_full = []\n",
    "for i in range(LOOKBACK, len(seq)):\n",
    "    X_full.append(seq[i-LOOKBACK:i])\n",
    "X_full = np.array(X_full).reshape(-1, LOOKBACK, 1)\n",
    "\n",
    "# train a small univariate LSTM on the full sequence\n",
    "uni_model = Sequential([\n",
    "    LSTM(LSTM_UNITS, input_shape=(LOOKBACK,1), return_sequences=False),\n",
    "    Dropout(LSTM_DROPOUT),\n",
    "    Dense(1)\n",
    "])\n",
    "uni_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=LR), loss='mse')\n",
    "uni_model.fit(X_full, seq[LOOKBACK:].reshape(-1,1), epochs=EPOCHS, batch_size=BATCH_SIZE, validation_split=0.05, shuffle=False, callbacks=[EarlyStopping(patience=PATIENCE, restore_best_weights=True)], verbose=0)\n",
    "print('Univariate LSTM trained for future MC forecasting.')\n",
    "\n",
    "# MC Dropout forecasts\n",
    "mc_paths = []\n",
    "for mc in range(N_MC_SAMPLES):\n",
    "    hist = seq.copy().tolist()\n",
    "    path = []\n",
    "    for t in range(FORECAST_HORIZON):\n",
    "        window = np.array(hist[-LOOKBACK:]).reshape(1, LOOKBACK, 1)\n",
    "        yhat = float(uni_model(window, training=True).numpy()[0,0])  # enable dropout at inference\n",
    "        path.append(yhat)\n",
    "        hist.append(yhat)\n",
    "    mc_paths.append(path)\n",
    "\n",
    "mc_paths = np.array(mc_paths)\n",
    "mean_scaled = mc_paths.mean(axis=0)\n",
    "lower_scaled = np.quantile(mc_paths, 0.025, axis=0)\n",
    "upper_scaled = np.quantile(mc_paths, 0.975, axis=0)\n",
    "\n",
    "lstm_mean_future = inv_scale(mean_scaled)\n",
    "lstm_lower_future = inv_scale(lower_scaled)\n",
    "lstm_upper_future = inv_scale(upper_scaled)\n",
    "\n",
    "plot_with_bands(fe.index, fe[TARGET_COL].values, future_index, lstm_mean_future, lstm_lower_future, lstm_upper_future,\n",
    "                f'LSTM (MC Dropout) — {FORECAST_HORIZON}-day Forecast with 95% bands')\n",
    "print('LSTM summary:', summarize_trend_and_uncertainty(lstm_mean_future, lstm_lower_future, lstm_upper_future))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9112fc0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Side-by-side metrics and automated interpretation for Task 3 forecasts\n",
    "import pandas as pd\n",
    "arima_summary = summarize_trend_and_uncertainty(arima_mean_future, arima_lower_future, arima_upper_future)\n",
    "lstm_summary  = summarize_trend_and_uncertainty(lstm_mean_future, lstm_lower_future, lstm_upper_future)\n",
    "\n",
    "print('\\n=== Automated Interpretation ===\\n')\n",
    "def interpret(summary, label):\n",
    "    slope = summary['slope']\n",
    "    trend = 'upward' if slope>0 else ('downward' if slope<0 else 'flat')\n",
    "    widen = summary['widen_rate']\n",
    "    widen_note = 'widening' if widen>0.05 else ('narrowing' if widen<-0.05 else 'stable')\n",
    "    print(f'[{label}] Trend: {trend} (slope={slope:.6f}), intervals are {widen_note} over the horizon.')\n",
    "\n",
    "interpret(arima_summary, 'ARIMA/SARIMA')\n",
    "interpret(lstm_summary, 'LSTM (MC Dropout)')\n",
    "\n",
    "# Opportunities & risks (simple heuristics)\n",
    "def opp_risk(mean_vals, lower_vals, upper_vals, label):\n",
    "    exp_change = (mean_vals[-1] - mean_vals[0]) / (mean_vals[0]+1e-9)\n",
    "    downside = (lower_vals[-1] - mean_vals[-1]) / (mean_vals[-1]+1e-9)\n",
    "    upside = (upper_vals[-1] - mean_vals[-1]) / (mean_vals[-1]+1e-9)\n",
    "    print(f'\\n[{label}] Expected change: {exp_change*100:.2f}%. Downside tail: {downside*100:.2f}%. Upside tail: {upside*100:.2f}%')\n",
    "\n",
    "opp_risk(arima_mean_future, arima_lower_future, arima_upper_future, 'ARIMA')\n",
    "opp_risk(lstm_mean_future, lstm_lower_future, lstm_upper_future, 'LSTM')\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
